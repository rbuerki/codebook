{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in progress - Note to myself, still to do:\n",
    "    - test error calculation on X_train vs full X\n",
    "    - implement a better way for feature reduction (Lasso or backward approach from ML-Statistics book)\n",
    "    - play around with Ridge / Lasso / Elastic Net Option\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alpha : {float, array-like}, shape (n_targets). Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to C^-1 in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.\n",
    "- fit_intercept : boolean Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).\n",
    "- normalize : boolean, optional, default False This parameter is ignored when fit_intercept is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use sklearn.preprocessing.StandardScaler before calling fit on an estimator with normalize=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing is not sophisticated at all, but \n",
    "- numerical data is normalized, \n",
    "- NaN are removed, \n",
    "- and there is One-Hot-Encoding for the categorical data.\n",
    "\n",
    "**Note:** If the data is already centered and you want `fit_intercept = False`, then normalization will not be applied. See [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) for more info, and see Bycicle notebook for an example with centered data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of LinRegModel Class and it's Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.utils import resample  # for error calculation of feature weights\n",
    "\n",
    "from helpers import EDA_functions, cleaning_functions\n",
    "import LinRegModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# display all columns in df\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('../data/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null float64\n",
      "total_rooms           20640 non-null float64\n",
      "total_bedrooms        20433 non-null float64\n",
      "population            20640 non-null float64\n",
      "households            20640 non-null float64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null float64\n",
      "ocean_proximity       20640 non-null object\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>-118.28</td>\n",
       "      <td>34.01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1.8656</td>\n",
       "      <td>122900.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>-118.13</td>\n",
       "      <td>34.02</td>\n",
       "      <td>43.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.9044</td>\n",
       "      <td>172900.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15376</th>\n",
       "      <td>-117.25</td>\n",
       "      <td>33.37</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>1.9950</td>\n",
       "      <td>146900.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "4968     -118.28     34.01                50.0       2601.0           794.0   \n",
       "7145     -118.13     34.02                43.0        396.0            91.0   \n",
       "15376    -117.25     33.37                 8.0       1755.0           530.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "4968       3080.0       770.0         1.8656            122900.0   \n",
       "7145        261.0        73.0         2.9044            172900.0   \n",
       "15376      1687.0       511.0         1.9950            146900.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "4968        <1H OCEAN  \n",
       "7145        <1H OCEAN  \n",
       "15376       <1H OCEAN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaning_functions.plot_NaN(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN per column:\n",
      "total_bedrooms: 207 (0.01%)\n"
     ]
    }
   ],
   "source": [
    "cleaning_functions.list_NaN(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for one-step LinReg modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for cleaning, preparing, fitting and evaluating LinReg model:\n",
    "\n",
    "**Attention**:\n",
    "- All columns with dtype object and category will be one-hot-encoded. Make shure they all have categorical character\n",
    "- All NaN in numerical cols will be imputed with mean\n",
    "- All NaN in non-numerical cols are mixed in zero category, for own column change 'dummy_na' parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(normalize=True)\n",
    "\n",
    "linReg_simple = LinRegModel.LinRegModel(housing, 'median_house_value', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linReg_simple.go_quickDirty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linReg_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- RMSE has to be calculated from MSE. Both are sensitive to outliers. If you have lot's of outliers MAE might be preferable.\n",
    "- R2-score can be problematic, there is also an adjusted R2-score to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization, Feature Selection and Feature Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to a very interesting [blog post on \"Diving Into Data\"](http://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/) regularized linear models are a powerful tool for feature interpretation and selection if you are aware of the following:\n",
    "- _L1 / Lasso_ produces sparse solutions and as such is very useful _selecting a strong subset of features_ for improving model performance. But it is not stable enough to provide a trustworthy interpretation of feature importance as even small changes to the data can massively change the coefficients.\n",
    "- _L2 / Ridge_ on the other hand can be used for _data interpretation_ due to its stability and the fact that useful features tend to have non-zero coefficients. \n",
    "\n",
    "__Why__: Generally in linear regression only the _residual sum of squares (RSS)_ is minimized, whereas in ridge and lasso regression, a _penalty is applied on coefficient values_ with the tuning parameter lambda (lambda=0 no penalty effect, lambda=large pushes coefficients towards / to zero).\n",
    "\n",
    "- _L2 / Ridge_ shrinks the weights according to their importance, but does not set them exactly to zero in order to eliminate unneccessary predictors from models. It will always include all the predictors. _Models from Ridge provide accuracy but are hard to interpret when the numer of predictors is large._\n",
    "- _L1 / Lasso_ on the other hand sets the weights of the unnecessary variables to zero and so eliminates them creating compact models that are easier to interpret. _Models from lasso are very much like subset selection_. The cost is less robustness.\n",
    "\n",
    "Further reading on regularization, 'Pyhton Data Science Handbook', p. 396f.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance / Coefficients\n",
    "***Attention: They may be completely different from those of an optimized model! See below.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default penalty on coefficients using linear regression in sklearn is a ridge (also known as an L2) penalty.  Because of this penalty, and because all the variables were normalized, we can look at the size of the coefficients in the model as an indication of the impact of each variable on the target variable. The larger the coefficient, the larger the expected impact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Overfitting / Features and Optimize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for finding an optimized model (with less overfitting thanks to a reduction in features).\n",
    "\n",
    "**Note:**\n",
    "- The decision on witch features are kept is depending on NaN, this is not good. I should be able to do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeLinModel(X, y, cutoffs, test_size = .30, random_state=42, plot=True):\n",
    "    '''\n",
    "    INPUT\n",
    "    X: pandas dataframe, X matrix\n",
    "    y: pandas dataframe, response variable\n",
    "    cutoffs: list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size: float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state: int, default 42, controls random state for train_test_split\n",
    "    plot: boolean, default 0.3, True to plot result\n",
    "\n",
    "    OUTPUT\n",
    "    r2_scores_test: list of floats of r2 scores on the test data\n",
    "    r2_scores_train: list of floats of r2 scores on the train data\n",
    "    opt_model: model object from sklearn\n",
    "    X_train, X_test, y_train, y_test: output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        #reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "        #split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "        #fit the model and obtain pred response\n",
    "        lm_model = LinearRegression(normalize=True)\n",
    "        lm_model.fit(X_train, y_train)\n",
    "        y_test_preds = lm_model.predict(X_test)\n",
    "        y_train_preds = lm_model.predict(X_train)\n",
    "        #append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    best_cutoff = max(results, key=results.get)\n",
    "\n",
    "    #reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    #split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "    #fit the model\n",
    "    opt_model = LinearRegression(normalize=True)\n",
    "    opt_model.fit(X_train, y_train)\n",
    "\n",
    "    return r2_scores_test, r2_scores_train, opt_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffs here pertains to the number of missing values allowed in the used columns.\n",
    "#Therefore, lower values for the cutoff provides more predictors in the model.\n",
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 25]\n",
    "\n",
    "#Run this cell to pass your X and y to the model for testing\n",
    "r2_scores_test, r2_scores_train, opt_model, X_train, X_test, y_train, y_test = optimizeLinModel(X, y, cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats for optimized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[1]) #Number of features\n",
    "print(r2_scores_test[np.argmax(r2_scores_test)]) # The model we should implement test_r2\n",
    "print(r2_scores_train[np.argmax(r2_scores_test)]) # The model we should implement train_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance / Coefficients - for optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = coef_weights(opt_model, X_train)\n",
    "coef_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
